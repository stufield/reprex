---
title: "Simulation Highlighting Effect of Class Imbalance on Prediction Accuracy"
subtitle: "This is somewhat frightening: a cautionary tail of balance"
author: "Stu Field"
date: "`r format(Sys.Date(), '%e %B %Y')`"
output:
  html_document:
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options:
  chunk_output_type: console
fontsize: 12pt
code_folding: show
ratio: '9:16'
---


```{r setup, echo = FALSE, message = FALSE}
library(magrittr)
library(dplyr)
library(purrr)
library(tibble)
library(ggplot2)
library(yardstick)
```


------------------------


# Setup

* Logistic regression binary classification model.
* Initial global data set of 400 samples -> 50/50 classes.
* Random split data into 200 training set; 200 test set.
* Test set is used for all Accuracy calculations.
* At each iteraton the training set is bootstrap sampled from class 1 *only*.
* At the same time, class 2 is down-sampled by the same amount,
  resulting in a larger and larger class-imbalance (1 > 2).



---------------


# Simulate some easy data to predict classes
```{r sim_data}
set.seed(1)
n <- 800                                     # total global sample set size
sim_data <- tibble(F1 = rnorm(n),            # create tibble to hold data
                   F2 = rnorm(n)
                   ) %>%                     # 2 features; F1 & F2
  mutate(y  = rep(c(1, 2), each = n/2)) %>%  # add a class variable (1, 2)
  mutate(F1 = case_when(                     # For F1 only class 1
    y == 1 ~ F1 + runif(n, 1, 2),            # bump unif noise [1,2]
    TRUE ~ F1
    ),
    F2 = case_when(                          # For F2 only class 1
    y == 1 ~ F2 + runif(n, 1, 3),            # bump unif noise [1,3]
    TRUE ~ F2
  ),
  y  = factor(y)) %>%                        # convert -> factor for model building
  mutate(id = row_number())                  # ID to track samples later
```


# Look at the simulated data on the 2 predictors; colored by class

```{r plot_scatter}
sim_data %>%
  ggplot(aes(x = F2, y = F1, colour = y)) +
  geom_point(alpha = 0.5, size = 4) +
  scale_colour_manual(values = c("blue", "red")) +
  NULL
```


# Random split of simulated data into 50/50 training and test sets

```{r train_test_sets}
set.seed(101)
train <- sim_data %>%              # using global `sim_data` as source
  sample_frac(0.5)                 # random select half of 200 samples for training
test <- sim_data %>%               # using global `sim_data` as source
  anti_join(train, by = "id") %>%  # merge on `id`s NOT present in the training set; the other 200
  dplyr::select(-id)               # remove the tracking field `id` from test
train %<>% dplyr::select(-id)      # remove the tracking field `id` from train
```


# Run the actual simulation

* increasing the class imbalance as it proceeds
* One-in-one out algorithm. Bootstrap add 1 sample from class 1
* Randomly remove 1 sample from class 2
* This generates a class imbalance but maintains training size

```{r simres}
simres <- seq(190) %>%                 # more iterations -> no class 2 left; trouble fitting
  purrr::map_df(~ {
    c1_boot <- train %>%               # create c1 training samples for this round
      dplyr::filter(y == 1) %>%        # filter only the class 1 samples
      sample_n(size = nrow(.) + .x,    # bootstrap class 1 samples
               replace = TRUE)         # with replacement

    c2_down <- train %>%               # create c2 training samples for this round
      dplyr::filter(y == 2) %>%        # filter only the class 2 samples
      sample_n(size = nrow(.) - .x)    # randomly downsample class 2; no replacement

    train_boot <- rbind(c1_boot, c2_down)  # combine boot c1 w down-sampled c2

    stopifnot(nrow(c1_boot) + nrow(c2_down) == nrow(train)) # sanity; stable size

    class_prop <- train_boot %>%       # calc. proportion c1
      pull(y) %>%                      # pull out `y` column; 
      equals(1) %>%                    # how many are "1"?
      mean()                           # the mean() of a logical is the proportion. Neat trick!
    
    # fit logistic-regression model
    logr <- stats::glm(y ~ .,                # y ~ F1 + F2
                       data = train_boot,    # use the new imbalanced training set
                       family = "binomial")  # `binomial` = logistic regression

    acc <- data.frame(
      truth = test$y,                        # true classnames from test set
      pred  = predict(logr, newdata = dplyr::select(test, -y), # prediced `probabilities`
                      type = "response")     # this ensures prob. space; not log-odds
      ) %>%
      mutate(pred = ifelse(pred < 0.5, 1, 2) %>% factor()) %>% # convert probs -> classes; 0.5 cutoff
      yardstick::accuracy(truth = truth, estimate = pred) %>%  # use `yardstick` accuracy function
      pull(".estimate")

    tibble(n1            = nrow(c1_boot),    # collect output in `tibble`
           n2            = nrow(c2_down),    # number of class 2
           class_balance = class_prop,       # class 1 proportion
           accuracy      = acc)              # accuracy
  })

simres         # view the `tibble` of the simulation
```


--------------


# Class imbalance vs. prediction accuracy

* Simulation statrs at 51.5% class 1; Accuracy = 0.855
* Simulation ends at 98.8% class 1; Accuracy = 0.648

```{r plot_imbalance}
simres %>%
  ggplot(aes(x = class_balance, y = accuracy)) +
  geom_point(alpha = 0.5, size = 2) +
  geom_smooth(method = "loess") +
  labs(x = "Class 1 Proportion", y = "Prediction Accuracy",
       title = "Logistic Regression | Accuracy vs. Class Imbalance")
```


-----------------


Created by [Rmarkdown](https://github.com/rstudio/rmarkdown)
(v`r utils::packageVersion("rmarkdown")`) and `r R.version$version.string`. 
